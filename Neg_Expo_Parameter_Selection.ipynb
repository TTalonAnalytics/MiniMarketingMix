{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "#import matplotlib.pyplot as plt\n",
    "import statsmodels.stats.outliers_influence as sif\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "# Read recipe inputs\n",
    "overall_final_modelling_data = dataiku.Dataset(\"overall_final_modelling_data\")\n",
    "overall_final_modelling_data_df = overall_final_modelling_data.get_dataframe()\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "# Declare type by which user want to select the curvature and Lambda value (assign Loop_Type as 'Automated' to get curvature and lambda from code)\n",
    "\n",
    "Loop_Type = 'Automated'\n",
    "\n",
    "# declare the number of sales lag and addstock to be calculated below\n",
    "var_sales_lags = 3\n",
    "var_promo_lags = 2\n",
    "\n",
    "# declare the starting month of the modelling time\n",
    "var_PERIOD_START = 201907\n",
    "\n",
    "# declare all variables\n",
    "# for lags and addstock call\n",
    "var_CHANNEL =   ['total_calls','total_200_syr_sample','total_300_syr_sample','total_speaker']\n",
    "\n",
    "#additional variable for COVID or market event or seasonality variable\n",
    "special_var = 'mobility_index'\n",
    "\n",
    "# for Impact calculation adding the COVID or market event or seasonality variable\n",
    "var_CHANNEL_1 =   ['total_calls','total_200_syr_sample','total_300_syr_sample','total_speaker','mobility_index']\n",
    "\n",
    "#Enter the cost of each promotion channel and NRx cost\n",
    "var_prom_cost_unit_final = [250,76,60,100] #enter the promotion unit price for each promotion channel in the same order as var_CHANNEL is declared\n",
    "var_sup = 1097  #per unit price of Rx\n",
    "#######################################################################################################################\n",
    "\n",
    "# combining sales and sample variable\n",
    "\n",
    "overall_final_modelling_data_df['total_sales']= overall_final_modelling_data_df['overall_nrx']\n",
    "overall_final_modelling_data_df['total_200_syr_sample']= overall_final_modelling_data_df['overall_samples_200_syr']\n",
    "overall_final_modelling_data_df['total_300_syr_sample']= overall_final_modelling_data_df['overall_samples_300_syr']\n",
    "overall_final_modelling_data_df['total_calls']= overall_final_modelling_data_df['overall_calls']\n",
    "overall_final_modelling_data_df['total_speaker']= overall_final_modelling_data_df['overall_speaker']\n",
    "\n",
    "overall_final_modelling_data_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main code for MMX\n",
    "\n",
    "\n",
    "#Sorting data on HCP ID and YearMonth\n",
    "overall_final_modelling_data_df.sort_values(['regid', 'month_id'], inplace=True)\n",
    "\n",
    "#Function to calculate sales and promotional lags\n",
    "def lag(overall_final_modelling_data_df, var, group_var, new_var,j) :\n",
    "    overall_final_modelling_data_df[new_var] = overall_final_modelling_data_df.groupby(group_var)[var].shift(j)\n",
    "    overall_final_modelling_data_df[new_var].fillna(0, inplace=True)\n",
    "    return overall_final_modelling_data_df\n",
    "\n",
    "#Calculating target variable (i.e., sales) lags on input data (add the lag range in the above part of the code)\n",
    "for i in range(1, var_sales_lags+1) :\n",
    "    new_variable = 'total_sales' + \"_\" + str(i)\n",
    "    overall_final_modelling_data_df = lag(overall_final_modelling_data_df, 'total_sales', 'regid', new_variable, i)\n",
    "\n",
    "\n",
    "#Calculating promotional lags for various channels on input data\n",
    "for i in range(0,len(var_CHANNEL)) :\n",
    "    for j in range(1,var_promo_lags+1) :\n",
    "        new_variable=var_CHANNEL[i]+\"_\"+str(j)\n",
    "        overall_final_modelling_data_df=lag(overall_final_modelling_data_df, var_CHANNEL[i], 'regid', new_variable, j)\n",
    "\n",
    "#Filtering input data on the basis of analysis period\n",
    "model_data = overall_final_modelling_data_df[overall_final_modelling_data_df['month_id'] >= var_PERIOD_START]\n",
    "\n",
    "#Getting list of unique segments\n",
    "segments = list(model_data['segment'].unique())\n",
    "\n",
    "#Getting list of unique year-months\n",
    "months=list(model_data['month_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting step-size for increasing curvature values\n",
    "\n",
    "\n",
    "#Storing curvature values for different channel segment combination in a dataf\n",
    "\n",
    "C_channel_seg={}\n",
    "C_channel_seg['Segment']=[]\n",
    "for i in range(0,len(segments)) :\n",
    "    for j in range(0,4) :\n",
    "        C_channel_seg['Segment'].append(segments[i])\n",
    "\n",
    "for i in range(0,len(var_CHANNEL)) :\n",
    "    new_var=\"C_\"+var_CHANNEL[i]\n",
    "    C_channel_seg[new_var]=[]\n",
    "    for j in range(0,len(segments)) :\n",
    "        channel_segment_mean=model_data.loc[(model_data['segment']==segments[j]) & (model_data[var_CHANNEL[i]]>0),var_CHANNEL[i]].mean()\n",
    "        mean_range=[x/channel_segment_mean for x in range(1,5)]\n",
    "        C_channel_seg[new_var].extend(mean_range)\n",
    "\n",
    "Curvature_channel_seg=pd.DataFrame(C_channel_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C_channel_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Calculating Best C Value for Channel Segment Combination ##################\n",
    "import statsmodels.api as sm\n",
    "\n",
    "Coeff_Final=pd.DataFrame()\n",
    "\n",
    "#selecting a segment\n",
    "for i in range(0,len(segments)) :\n",
    "    #subsetting model data for a segment\n",
    "    seg_data=model_data[model_data['segment']==segments[i]]\n",
    "\n",
    "    for j in range(0,len(var_CHANNEL)) :\n",
    "        for l in range(1,5) :\n",
    "            adstock=seg_data[var_CHANNEL[j]]\n",
    "            for lam in np.arange(.1,.9,.1):\n",
    "                for k in range(1,var_promo_lags+1) :\n",
    "\n",
    "                    channel_lag=var_CHANNEL[j]+\"_\"+str(k)\n",
    "                    adstock = adstock + (lam**k)*seg_data[channel_lag] #.33 is the the lambda value, we can take it as user input in future\n",
    "\n",
    "                var='C_'+var_CHANNEL[j]\n",
    "                Curvature=[]\n",
    "                Curv=Curvature_channel_seg.loc[Curvature_channel_seg['Segment']==segments[i],var]\n",
    "                Curv=pd.DataFrame(Curv)\n",
    "                Curv=Curv.iloc[l-1,:]\n",
    "                C=pd.DataFrame(Curv)\n",
    "                Curvature.append(Curv)\n",
    "                seg_data[var_CHANNEL[j]+'_t']=1-np.exp(-1*Curv[0]*adstock)\n",
    "                X_Sales_Lag_Cols=['total_sales' + '_' +\n",
    "                                str(lag_num) for lag_num in\n",
    "                                range(1, var_sales_lags+1)]\n",
    "                X_Sales_Lag_Cols.append(var_CHANNEL[j] + '_t')\n",
    "                Y_Cols = ['total_sales']\n",
    "                X = seg_data[X_Sales_Lag_Cols]\n",
    "                Y = seg_data[Y_Cols]\n",
    "                X = sm.add_constant(X)\n",
    "                model = sm.OLS(Y, X).fit()\n",
    "                fit_summary = pd.DataFrame(model.summary2().tables[1])\n",
    "                fit_summary = fit_summary.reset_index()\n",
    "                fit_summary_2 = pd.DataFrame(model.summary2().tables[0])\n",
    "                Coeff = fit_summary[['index', 'Coef.', 'Std.Err.']]\n",
    "                Coeff['adj r2'] = fit_summary_2.iloc[0,3]\n",
    "                Coeff['Segment'] = segments[i]\n",
    "                Coeff['Curavture'] = C.iloc[0,0]\n",
    "                Coeff['Lambda'] = lam\n",
    "                Coeff.columns = ['Variable', 'Coeff', 'P-Value', 'Adj R-Sq',\n",
    "                                   'Segment', 'Curvature','Lambda']\n",
    "                #Appending model_summaries\n",
    "                Coeff_Final = pd.concat([Coeff_Final, Coeff], axis=0)\n",
    "#print(Coeff_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Coeff_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Selecting Best C Value for channel segment combination ##############################\n",
    "\n",
    "channel_name_transformed=[]\n",
    "for i in var_CHANNEL :\n",
    "    tranformed_channel_name=i+'_t'\n",
    "    channel_name_transformed.append(tranformed_channel_name)\n",
    "Coeff_Final=Coeff_Final[Coeff_Final['Variable'].isin(channel_name_transformed)]\n",
    "Coeff_Final.reset_index(drop=True,inplace=True)\n",
    "\n",
    "Coeff_Best_Model = Coeff_Final[Coeff_Final['Adj R-Sq'] == Coeff_Final.groupby(['Segment','Variable'])['Adj R-Sq'].transform(max)]\n",
    "Coeff_Best_Model = Coeff_Final[Coeff_Final['P-Value'] == Coeff_Final.groupby(['Segment','Variable'])['P-Value'].transform(min)]\n",
    "Coeff_Best_Model = Coeff_Best_Model[Coeff_Best_Model['Curvature'] == Coeff_Best_Model.groupby(['Segment','Variable'])['Curvature'].transform(min)]\n",
    "Coeff_Best_Model = Coeff_Best_Model[Coeff_Best_Model['Lambda'] == Coeff_Best_Model.groupby(['Segment','Variable'])['Lambda'].transform(max)]\n",
    "Coeff_Best_Model.reset_index(drop=True,inplace=True)\n",
    "Coeff_Best_Model=Coeff_Best_Model[['Variable','Segment','Adj R-Sq','Curvature','Lambda']]\n",
    "#Channel_Equation=pd.DataFrame(zip(var_CHANNEL,equation_final),\n",
    "#                              columns=['Variable','Equation'])\n",
    "\n",
    "#Creating flag in overall curvature values\n",
    "#Coeff_Final_1 = pd.merge(Coeff_Best_Model,Coeff_Final, how='left',on=['Variable','Segment','Curvature','Lambda'])\n",
    "#Coeff_Final_1['Flag']=1\n",
    "# Coeff_Final = pd.merge(Coeff_Final_1,Coeff_Final, how='outer',on=['Variable','Segment','Curvature','Lambda'])\n",
    "# del Coeff_Final['Coeff_x'],Coeff_Final['P-Value_x'],Coeff_Final['Adj R-Sq_x']\n",
    "# Coeff_Final.columns = ['Variable', 'Segment', 'Curvature', 'Lambda','Flag', 'Coeff', 'P-Value', 'Adj R-Sq']\n",
    "# Coeff_Final.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################  Running Models #####################################################\n",
    "\n",
    "################### Calcualating Parameter Estimates ########################################\n",
    "\n",
    "\n",
    "\n",
    "#Function to generate the linear equation for Curve_fit\n",
    "\n",
    "if Loop_Type == \"Automated\" :\n",
    "\n",
    "    Parameter_Estimates=pd.DataFrame()\n",
    "    Final_Model_Data=pd.DataFrame()\n",
    "    vif=pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(segments)) :\n",
    "        seg_data=model_data[model_data['segment']==segments[i]]\n",
    "        Channel_transformed_names=[]\n",
    "        for j in range(0,len(var_CHANNEL)) :\n",
    "\n",
    "            adstock=seg_data[var_CHANNEL[j]]\n",
    "            variable=var_CHANNEL[j]+'_t'\n",
    "            lam=Coeff_Best_Model.loc[(Coeff_Best_Model['Segment']==segments[i]) & (Coeff_Best_Model['Variable']==variable),'Lambda']\n",
    "            lam=pd.DataFrame(lam)\n",
    "            for k in range(1,var_promo_lags+1) :\n",
    "                channel_lag=var_CHANNEL[j]+'_'+str(k)\n",
    "                adstock=adstock + (lam.iloc[0,0]**k)*seg_data[channel_lag]\n",
    "            Channel_transformed_names.append(variable)\n",
    "            Curv=Coeff_Best_Model.loc[(Coeff_Best_Model['Segment']==segments[i]) & (Coeff_Best_Model['Variable']==variable),'Curvature']\n",
    "            Curv=pd.DataFrame(Curv)\n",
    "            seg_data[variable]=adstock\n",
    "            seg_data[variable]=1-np.exp(-1*Curv.iloc[0,0]*adstock)\n",
    "\n",
    "\n",
    "        X_Sales_Lag_Cols=['total_sales' + '_' +\n",
    "                                str(lag_num) for lag_num in\n",
    "                                range(1, var_sales_lags+1)]\n",
    "        X_Sales_Lag_Cols.extend(Channel_transformed_names)\n",
    "        X_Sales_Lag_Cols.append(special_var)\n",
    "        Y_Cols=['total_sales']\n",
    "        X=seg_data[X_Sales_Lag_Cols]\n",
    "        Y=seg_data[Y_Cols]\n",
    "        vif['Variable'] = X.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X.values, m) for m in range(X.shape[1])]\n",
    "        X=sm.add_constant(X)\n",
    "\n",
    "        model=sm.OLS(Y,X).fit()\n",
    "        fit_summary = pd.DataFrame(model.summary2().tables[1])\n",
    "        fit_summary = fit_summary.reset_index()\n",
    "        fit_summary_2 = pd.DataFrame(model.summary2().tables[0])\n",
    "        Coeff = fit_summary[['index', 'Coef.', 'Std.Err.']]\n",
    "        Coeff['adj r2'] = fit_summary_2.iloc[0,3]\n",
    "        Coeff['R2'] = fit_summary_2.iloc[6,1]\n",
    "        #Coeff['R2'] = Coeff['R2'].astype(float)\n",
    "        #Coeff['VIF'] = 1/(1-pow(Coeff['R2'],2))\n",
    "        Coeff['Segment'] = segments[i]\n",
    "        Coeff.columns = ['Variable', 'Coeff', 'P-Value', 'Adj R-Sq','R2',\n",
    "                                   'Segment']\n",
    "\n",
    "        Coeff_list=list(Coeff['Coeff'])\n",
    "        X_Variable=list(Coeff['Variable'])\n",
    "        Coeff = pd.merge(Coeff,vif, how= 'left' ,on = 'Variable')\n",
    "\n",
    "        Coeff['Coeff']=Coeff_list\n",
    "        Final_Model_Data=pd.concat([Final_Model_Data,seg_data])  #creating addstock based on best C and lambda\n",
    "        Parameter_Estimates=pd.concat([Parameter_Estimates,Coeff],axis=0)\n",
    "\n",
    "\n",
    "    Parameter_Estimates.reset_index(drop=True,inplace=True)\n",
    "    Parameter_Estimates=Parameter_Estimates[['Variable','Segment','Coeff','P-Value', 'Adj R-Sq','R2','VIF']]\n",
    "\n",
    "else :\n",
    "    Coeff_Best_Model_1 = dataiku.Dataset(\"user_input\")\n",
    "    Coeff_Best_Model_1 = Coeff_Best_Model_1.get_dataframe()\n",
    "    Parameter_Estimates=pd.DataFrame()\n",
    "    Final_Model_Data=pd.DataFrame()\n",
    "    vif=pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(segments)) :\n",
    "        seg_data=model_data[model_data['segment']==segments[i]]\n",
    "        Channel_transformed_names=[]\n",
    "        for j in range(0,len(var_CHANNEL)) :\n",
    "\n",
    "            adstock=seg_data[var_CHANNEL[j]]\n",
    "            variable=var_CHANNEL[j]+'_t'\n",
    "            lam=Coeff_Best_Model_1.loc[(Coeff_Best_Model_1['Segment']==segments[i]) & (Coeff_Best_Model_1['Variable']==variable),'Lambda']\n",
    "            lam=pd.DataFrame(lam)\n",
    "            for k in range(1,var_promo_lags+1) :\n",
    "                channel_lag=var_CHANNEL[j]+'_'+str(k)\n",
    "                adstock=adstock + (lam.iloc[0,0]**k)*seg_data[channel_lag]\n",
    "            Channel_transformed_names.append(variable)\n",
    "            Curv=Coeff_Best_Model_1.loc[(Coeff_Best_Model_1['Segment']==segments[i]) & (Coeff_Best_Model_1['Variable']==variable),'Curvature']\n",
    "            Curv=pd.DataFrame(Curv)\n",
    "            seg_data[variable]=adstock\n",
    "            seg_data[variable]=1-np.exp(-1*Curv.iloc[0,0]*adstock)\n",
    "\n",
    "\n",
    "        X_Sales_Lag_Cols=['total_sales' + '_' +\n",
    "                                str(lag_num) for lag_num in\n",
    "                                range(1, var_sales_lags+1)]\n",
    "        X_Sales_Lag_Cols.extend(Channel_transformed_names)\n",
    "        X_Sales_Lag_Cols.append(special_var)\n",
    "        Y_Cols=['total_sales']\n",
    "        X=seg_data[X_Sales_Lag_Cols]\n",
    "        Y=seg_data[Y_Cols]\n",
    "        vif['Variable'] = X.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X.values, m) for m in range(X.shape[1])]\n",
    "        X=sm.add_constant(X)\n",
    "\n",
    "        model=sm.OLS(Y,X).fit()\n",
    "        fit_summary = pd.DataFrame(model.summary2().tables[1])\n",
    "        fit_summary = fit_summary.reset_index()\n",
    "        fit_summary_2 = pd.DataFrame(model.summary2().tables[0])\n",
    "        Coeff = fit_summary[['index', 'Coef.', 'Std.Err.']]\n",
    "        Coeff['adj r2'] = fit_summary_2.iloc[0,3]\n",
    "        Coeff['R2'] = fit_summary_2.iloc[6,1]\n",
    "        #Coeff['R2'] = Coeff['R2'].astype(float)\n",
    "        #Coeff['VIF'] = 1/(1-pow(Coeff['R2'],2))\n",
    "        Coeff['Segment'] = segments[i]\n",
    "        Coeff.columns = ['Variable', 'Coeff', 'P-Value', 'Adj R-Sq','R2',\n",
    "                                   'Segment']\n",
    "\n",
    "        Coeff_list=list(Coeff['Coeff'])\n",
    "        X_Variable=list(Coeff['Variable'])\n",
    "        Coeff = pd.merge(Coeff,vif, how= 'left' ,on = 'Variable')\n",
    "\n",
    "        Coeff['Coeff']=Coeff_list\n",
    "        Final_Model_Data=pd.concat([Final_Model_Data,seg_data])  #creating addstock based on best C and lambda\n",
    "        Parameter_Estimates=pd.concat([Parameter_Estimates,Coeff],axis=0)\n",
    "\n",
    "\n",
    "    Parameter_Estimates.reset_index(drop=True,inplace=True)\n",
    "    Parameter_Estimates=Parameter_Estimates[['Variable','Segment','Coeff','P-Value', 'Adj R-Sq','R2','VIF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Parameter_Estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Calculating Impact ####################################\n",
    "\n",
    "######################### 1. Brand Equity #######################################\n",
    "\n",
    "BE_Impact=pd.DataFrame()\n",
    "for i in range(0,len(segments)) :\n",
    "        seg_data=Final_Model_Data[Final_Model_Data['segment']==segments[i]]\n",
    "        hcp_count=len(seg_data['regid'].unique())\n",
    "        coeff=Parameter_Estimates.loc[(Parameter_Estimates['Variable']=='const') & (Parameter_Estimates['Segment']==segments[i]),'Coeff']\n",
    "        sales_lag_coeffs=[]\n",
    "        for j in range(1, var_sales_lags+1) :\n",
    "            s = 'total_sales' + '_' + str(j)\n",
    "            sales_lag_coeffs.extend(list(Parameter_Estimates.loc[((Parameter_Estimates['Segment']==segments[i]) & (Parameter_Estimates['Variable']==s)),'Coeff']))\n",
    "        Monthly_BEs=[]\n",
    "        for month in range(0,len(months)) :\n",
    "            if month == 0 :\n",
    "                Monthly_BEs.append(coeff.iloc[0])\n",
    "            else :\n",
    "                iters = min(month, 3)\n",
    "                brand_equity = coeff.iloc[0]\n",
    "                for k in range(0, iters) :\n",
    "                    brand_equity += (Monthly_BEs[month-1-k] * sales_lag_coeffs[k])\n",
    "                brand_equity = [brand_equity]\n",
    "                Monthly_BEs.extend(brand_equity)\n",
    "\n",
    "        seg_be=pd.DataFrame(zip(months,Monthly_BEs),\n",
    "                            columns=['month_id', 'Impact'])\n",
    "        seg_be['Impact'] = seg_be['Impact'] * hcp_count\n",
    "        seg_be['Segment'] = segments[i]\n",
    "        seg_be['Channel'] = 'Brand Equity'\n",
    "        BE_Impact = pd.concat([BE_Impact, seg_be], axis=0)\n",
    "\n",
    "NL_Months=[]\n",
    "NL_BE_Impact=[]\n",
    "\n",
    "for i in months :\n",
    "        NL_Months.append(i)\n",
    "        NL_BE_Impact.append(BE_Impact[BE_Impact['month_id']==i]['Impact'].sum())\n",
    "BE_Impact_NL=pd.DataFrame(zip(NL_Months,NL_BE_Impact),\n",
    "                              columns=['month_id', 'Impact'])\n",
    "BE_Impact_NL['Segment']='National'\n",
    "BE_Impact_NL['Channel'] = 'Brand Equity'\n",
    "BE_Impact=pd.concat([BE_Impact,BE_Impact_NL],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 2. Carryover #######################################\n",
    "\n",
    "CO_Impact = pd.DataFrame()\n",
    "for i in range(0, len(segments)) :\n",
    "\n",
    "    seg_data=Final_Model_Data[Final_Model_Data['segment'] == segments[i]]\n",
    "\n",
    "\n",
    "    Previous_Sales=[]\n",
    "    for j in range(var_sales_lags, 0, -1) :\n",
    "\n",
    "        s = 'total_sales'+'_'+str(j)\n",
    "        Previous_Sales.append(seg_data.loc[seg_data['month_id']==var_PERIOD_START, s].sum())\n",
    "\n",
    "    sales_lag_coeffs=[]\n",
    "    for m in range(1, var_sales_lags+1) :\n",
    "        s = 'total_sales'+'_'+str(m)\n",
    "        sales_lag_coeffs.extend(Parameter_Estimates.loc[((Parameter_Estimates['Segment']==segments[i]) & (Parameter_Estimates['Variable']==s)),'Coeff'])\n",
    "\n",
    "    for k in range(0,len(months)) :\n",
    "        c = 0\n",
    "        for l in range(0, var_sales_lags) :\n",
    "            c += Previous_Sales[var_sales_lags+k-1-l] * sales_lag_coeffs[l]\n",
    "        Previous_Sales.append(c)\n",
    "\n",
    "    Previous_Sales=Previous_Sales[var_sales_lags:]\n",
    "    seg_impact = pd.DataFrame(zip(months, Previous_Sales),\n",
    "                              columns =['month_id', 'Impact'])\n",
    "    seg_impact['Segment'] = segments[i]\n",
    "    seg_impact['Channel'] = 'CarryOver'\n",
    "    CO_Impact = pd.concat([CO_Impact, seg_impact], axis=0)\n",
    "\n",
    "\n",
    "NL_Months=[]\n",
    "NL_CO_Impact=[]\n",
    "for i in months :\n",
    "    NL_Months.append(i)\n",
    "    NL_CO_Impact.append(CO_Impact[CO_Impact['month_id']==i]['Impact'].sum())\n",
    "\n",
    "CO_Impact_NL=pd.DataFrame(zip(NL_Months,NL_CO_Impact),\n",
    "                          columns=['month_id', 'Impact'])\n",
    "CO_Impact_NL['Segment']='National'\n",
    "CO_Impact_NL['Channel'] = 'CarryOver'\n",
    "CO_Impact=pd.concat([CO_Impact,CO_Impact_NL],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Model_Data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# 3. CHANNEL IMPACT #############################################\n",
    "\n",
    "Prom_Impact=pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(segments)) :\n",
    "    seg_data = Final_Model_Data[Final_Model_Data['segment'] == segments[i]]\n",
    "    for j in range(0,len(var_CHANNEL_1)) :\n",
    "        if var_CHANNEL_1[j]==special_var :\n",
    "            s=var_CHANNEL_1[j]\n",
    "        else:\n",
    "            s=var_CHANNEL_1[j]+\"_t\"\n",
    "\n",
    "        coeff = Parameter_Estimates.loc[(Parameter_Estimates['Segment'] == segments[i]) & (Parameter_Estimates['Variable'] == s) , 'Coeff']\n",
    "        sales_lag_coeffs = []\n",
    "        for m in range(1, var_sales_lags + 1) :\n",
    "            lag_var = 'total_sales' + '_' + str(m)\n",
    "            sales_lag_coeffs.extend(list(Parameter_Estimates.loc[((Parameter_Estimates['Segment'] == segments[i]) & (Parameter_Estimates['Variable'] == lag_var)), 'Coeff']))\n",
    "\n",
    "        Monthly_Impacts=[]\n",
    "        for month in range(0, len(months)) :\n",
    "            total_200_syr_sample=seg_data[seg_data['month_id'] == months[month]][s].sum()\n",
    "            if month == 0 :\n",
    "\n",
    "                impact = coeff * total_200_syr_sample\n",
    "                Monthly_Impacts.extend(impact)\n",
    "            else :\n",
    "\n",
    "                iters = min(month, var_sales_lags)\n",
    "                impact = coeff.iloc[0] * total_200_syr_sample\n",
    "                for z in range(0, iters) :\n",
    "\n",
    "                    impact += (Monthly_Impacts[month-1-z] * sales_lag_coeffs[z])\n",
    "                impact = [impact]\n",
    "                Monthly_Impacts.extend(impact)\n",
    "\n",
    "        seg_impact = pd.DataFrame(zip(months, Monthly_Impacts),\n",
    "                          columns =['month_id', 'Impact'])\n",
    "        seg_impact['Segment'] = segments[i]\n",
    "        seg_impact['Channel'] = var_CHANNEL_1[j]\n",
    "        Prom_Impact = pd.concat([Prom_Impact, seg_impact], axis=0)\n",
    "\n",
    "\n",
    "Prom_Impact_NL=Prom_Impact.groupby(['month_id','Channel'])['Impact'].sum().reset_index()\n",
    "Prom_Impact_NL.sort_values(['Channel'],inplace=True)\n",
    "Prom_Impact_NL['Segment']='National'\n",
    "Prom_Impact_NL=Prom_Impact_NL[['month_id','Impact','Segment','Channel']]\n",
    "Prom_Impact=pd.concat([Prom_Impact,Prom_Impact_NL],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Combining BE,CO and Promotional Impact into a single dataframe\n",
    "Final_Impact=(BE_Impact.append(CO_Impact)).append(Prom_Impact)\n",
    "Final_Impact.reset_index(drop=True,inplace=True)\n",
    "\n",
    "Overall_Impact = Final_Impact[Final_Impact['Segment']=='National']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Data With Impacts #####################################\n",
    "\n",
    "Final_Model_Data['const']=1\n",
    "Coeff_names=list(Parameter_Estimates['Variable'].unique())\n",
    "Model_Data_With_Impact=pd.DataFrame()\n",
    "for i in range(0,len(segments)) :\n",
    "    seg_data=Final_Model_Data[Final_Model_Data['segment']==segments[i]]\n",
    "    for j in range(0,len(Coeff_names)) :\n",
    "        var=Coeff_names[j]+\"_Impact\"\n",
    "        Coeff=Parameter_Estimates.loc[(Parameter_Estimates['Segment']==segments[i]) & (Parameter_Estimates['Variable']==Coeff_names[j]),'Coeff']\n",
    "        seg_data[var]=seg_data[Coeff_names[j]]*Coeff.iloc[0]\n",
    "    Model_Data_With_Impact=pd.concat([Model_Data_With_Impact,seg_data],axis=0)\n",
    "\n",
    "Model_Data_With_Impact=Model_Data_With_Impact.loc[:,Model_Data_With_Impact.columns.str.contains('_Impact') | Model_Data_With_Impact.columns.isin(['regid','month_id'])]\n",
    "\n",
    "Model_Data_With_Impact_Final= Model_Data_With_Impact\n",
    "Model_Data_With_Impact_Final.fillna(0, inplace=True)\n",
    "carryover=0\n",
    "for i in range(1,var_sales_lags+1) :\n",
    "    var='total_sales'+'_'+str(i)+'_Impact'\n",
    "    carryover+=Model_Data_With_Impact_Final[var]\n",
    "Model_Data_With_Impact_Final['Carryover']=carryover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Final_Impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Summary ################################\n",
    "\n",
    "Seg_Channel_Hist_Dist=pd.DataFrame()\n",
    "for i in range(0,len(segments)) :\n",
    "    for j in range(0,len(var_CHANNEL_1)) :\n",
    "        Segment=segments[i]\n",
    "        Channel=var_CHANNEL_1[j]\n",
    "        seg_data=Final_Model_Data[Final_Model_Data['segment']==segments[i]]\n",
    "        hcp_count=seg_data['regid'].nunique()\n",
    "        Months=len(months)\n",
    "        Promotion=seg_data[var_CHANNEL_1[j]].sum()\n",
    "        Sales=seg_data['total_sales'].sum()\n",
    "        Hist_Dist=pd.DataFrame({'Segment':[Segment],'Channel':[Channel],'HCP Count':[hcp_count],\n",
    "                                   'Channel_Promotion':[Promotion],'Sales':[Sales],'Months':[Months]})\n",
    "        Seg_Channel_Hist_Dist=pd.concat([Seg_Channel_Hist_Dist,Hist_Dist],axis=0)\n",
    "\n",
    "Seg_Channel_Hist_Dist.reset_index(inplace=True,drop=True)\n",
    "\n",
    "Overall_Channel_Hist_Dist=pd.DataFrame(Final_Model_Data[var_CHANNEL_1].sum())\n",
    "Overall_Channel_Hist_Dist.reset_index(inplace=True)\n",
    "Overall_Channel_Hist_Dist.columns=['Channel','Total_Promotion']\n",
    "Seg_Channel_Hist_Dist=pd.merge(Seg_Channel_Hist_Dist,Overall_Channel_Hist_Dist,\n",
    "                               on='Channel',how='inner')\n",
    "Seg_Channel_Hist_Dist['Promotion_Dist_Across_Segment']=Seg_Channel_Hist_Dist['Channel_Promotion']/Seg_Channel_Hist_Dist['Total_Promotion']\n",
    "Data_Summary_Final=Seg_Channel_Hist_Dist\n",
    "Data_Summary_Final=Data_Summary_Final[['Segment','Channel','Channel_Promotion','Total_Promotion','Promotion_Dist_Across_Segment','HCP Count','Months']]\n",
    "\n",
    "\n",
    "sales_lag_names=[]\n",
    "for i in range(1,var_sales_lags+1) :\n",
    "    k='total_sales'+\"_\"+str(i)\n",
    "    sales_lag_names.append(k)\n",
    "\n",
    "Sales_lag_Coeff=Parameter_Estimates.loc[Parameter_Estimates['Variable'].isin(sales_lag_names),\n",
    "                                        ['Segment','Variable','Coeff']]\n",
    "\n",
    "Sales_lag_Coeff.reset_index(inplace=True,drop=True)\n",
    "\n",
    "Short_Term_Factor=pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(segments)) :\n",
    "    sales_lag=[]\n",
    "    Monthly_Sales_STF=[]\n",
    "    for k in range(1,var_sales_lags+1) :\n",
    "            s='total_sales'+\"_\"+str(k)\n",
    "            p=list(Sales_lag_Coeff.loc[(Sales_lag_Coeff['Segment']==segments[i]) & (Sales_lag_Coeff['Variable']==s),'Coeff'])\n",
    "            sales_lag.extend(p)\n",
    "\n",
    "    for month in range(0,len(months)) :\n",
    "            if month==0:\n",
    "                impact=1\n",
    "                Monthly_Sales_STF.append(impact)\n",
    "\n",
    "            else :\n",
    "                iters=min(month,var_sales_lags)\n",
    "                impact=1\n",
    "                for z in range(0,iters) :\n",
    "                    impact+=Monthly_Sales_STF[month-1-z]*sales_lag[z]\n",
    "                Monthly_Sales_STF.append(impact)\n",
    "    Total_STF=sum(Monthly_Sales_STF)/len(months)\n",
    "    STF=pd.DataFrame({'Segment':[segments[i]],'STF':[Total_STF]})\n",
    "    Short_Term_Factor=pd.concat([Short_Term_Factor,STF],axis=0)\n",
    "    Short_Term_Factor.reset_index(drop=True,inplace=True)\n",
    "\n",
    "Data_Summary_Final=pd.merge(Data_Summary_Final,Short_Term_Factor,on=['Segment'],how='inner')\n",
    "\n",
    "Long_Term_Factor=pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(segments)) :\n",
    "    Monthly_Sales_LTF=[]\n",
    "    sales_lag = []\n",
    "    for k in range(1,var_sales_lags+1) :\n",
    "            s='total_sales'+\"_\"+str(k)\n",
    "            p=list(Sales_lag_Coeff.loc[(Sales_lag_Coeff['Segment']==segments[i]) & (Sales_lag_Coeff['Variable']==s),'Coeff'])\n",
    "            sales_lag.extend(p)\n",
    "\n",
    "    for month in range(0,36) :\n",
    "        if month == 0:\n",
    "            impact=1\n",
    "            Monthly_Sales_LTF.append(impact)\n",
    "\n",
    "        elif (~(month==0) & (month<len(months))) :\n",
    "\n",
    "            iters=min(month,var_sales_lags)\n",
    "            impact=1\n",
    "            for z in range(0,iters) :\n",
    "\n",
    "                impact+=Monthly_Sales_LTF[month-1-z]*sales_lag[z]\n",
    "            Monthly_Sales_LTF.append(impact)\n",
    "\n",
    "        else :\n",
    "\n",
    "            iters=min(month,var_sales_lags)\n",
    "            impact=0\n",
    "            for z in range(0,iters) :\n",
    "\n",
    "                impact+=Monthly_Sales_LTF[month-1-z]*sales_lag[z]\n",
    "            Monthly_Sales_LTF.append(impact)\n",
    "\n",
    "    Total_LTF=sum(Monthly_Sales_LTF)/len(months)\n",
    "    LTF=pd.DataFrame({'Segment' : [segments[i]],'LTF' : [Total_LTF]})\n",
    "    Long_Term_Factor=pd.concat([Long_Term_Factor,LTF],axis=0)\n",
    "    Long_Term_Factor.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "Data_Summary_Final=pd.merge(Data_Summary_Final,Long_Term_Factor,on=['Segment'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Data_Summary_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# ROI Calculation ######################################\n",
    "Annual_Impact=pd.DataFrame(Final_Impact.groupby(['Segment','Channel'],as_index=False)['Impact'].sum())\n",
    "Annual_Impact=Annual_Impact[~Annual_Impact['Channel'].isin(['Brand Equity','CarryOver'])]\n",
    "Annual_Impact.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "Annual_Impact=pd.merge(Annual_Impact,Data_Summary_Final[['Segment','Channel','Channel_Promotion']],how='inner',on=['Segment','Channel'])\n",
    "Channel_Cost=pd.DataFrame()\n",
    "for i in range(0,len(var_CHANNEL)) :\n",
    "    Channel_Name=[var_CHANNEL[i]]\n",
    "    Channel_Unit_Promotion_Cost=[var_prom_cost_unit_final[i]]\n",
    "    Cost=pd.DataFrame(zip(Channel_Name,Channel_Unit_Promotion_Cost),\n",
    "                      columns=['Channel','Cost'])\n",
    "    Channel_Cost=pd.concat([Channel_Cost,Cost],axis=0)\n",
    "Channel_Cost.reset_index(inplace=True,drop=True)\n",
    "\n",
    "Annual_Impact=pd.merge(Annual_Impact,Channel_Cost,how='inner',on=['Channel'])\n",
    "Annual_Impact['sale_per_unit']=var_sup\n",
    "\n",
    "\n",
    "LTF_df = Parameter_Estimates.loc[Parameter_Estimates['Variable'].str.contains('total_sales'),\n",
    "                                ['Segment','Variable','Coeff']]\n",
    "\n",
    "LTF_df=LTF_df.groupby(['Segment'],as_index=False)['Coeff'].sum()\n",
    "LTF_df.loc[LTF_df['Coeff']>=1,'Coeff']=0.99\n",
    "LTF_df['LTF']=1/(1-LTF_df['Coeff'])\n",
    "\n",
    "ROI_df=pd.merge(Annual_Impact,LTF_df[['Segment','LTF']],how='inner',on=['Segment'])\n",
    "ROI_df['Long_Term_Impact']=ROI_df['Impact']*ROI_df['LTF']\n",
    "ROI_df['Short_Term_Sales']=ROI_df['Impact']*ROI_df['sale_per_unit']\n",
    "ROI_df['Long_Term_Sales']=ROI_df['Long_Term_Impact']*ROI_df['sale_per_unit']\n",
    "ROI_df['Total_Spend']=ROI_df['Channel_Promotion']*ROI_df['Cost']\n",
    "ROI_df['Short_Term_ROI(%)']=(ROI_df['Short_Term_Sales']/ROI_df['Total_Spend'])*100\n",
    "ROI_df['Long_Term_ROI(%)']=(ROI_df['Long_Term_Sales']/ROI_df['Total_Spend'])*100\n",
    "\n",
    "ROI_df=ROI_df[['Segment','Channel','Short_Term_Sales','Long_Term_Sales','Total_Spend','Short_Term_ROI(%)','Long_Term_ROI(%)']]\n",
    "\n",
    "National_ROI_df=ROI_df.groupby(['Channel'],as_index=False)[['Short_Term_Sales','Long_Term_Sales','Total_Spend']].sum()\n",
    "National_ROI_df['Short_Term_ROI(%)']=(National_ROI_df['Short_Term_Sales']/National_ROI_df['Total_Spend'])*100\n",
    "National_ROI_df['Long_Term_ROI(%)']=(National_ROI_df['Long_Term_Sales']/National_ROI_df['Total_Spend'])*100\n",
    "National_ROI_df['Segment']='National'\n",
    "National_ROI_df=National_ROI_df[['Segment','Channel','Short_Term_Sales','Long_Term_Sales','Total_Spend','Short_Term_ROI(%)','Long_Term_ROI(%)']]\n",
    "\n",
    "Final_ROI_df=pd.concat([ROI_df,National_ROI_df],axis=0)\n",
    "Final_ROI_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "\n",
    "################################ End of ROI Calculations###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Final_ROI_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
    "\n",
    "modelling_df = Final_Impact # For this sample code, simply copy input to output\n",
    "\n",
    "\n",
    "# Write recipe outputs\n",
    "final_impact = dataiku.Dataset(\"final_impact\")\n",
    "final_impact.write_with_schema(Final_Impact)\n",
    "\n",
    "curvature = dataiku.Dataset(\"curvature\")\n",
    "curvature.write_with_schema(Coeff_Final)\n",
    "\n",
    "if Loop_Type == \"Automated\" :\n",
    "    best_curvature = dataiku.Dataset(\"best_curvature\")\n",
    "    best_curvature.write_with_schema(Coeff_Best_Model)\n",
    "else :\n",
    "    best_curvature = dataiku.Dataset(\"best_curvature\")\n",
    "    best_curvature.write_with_schema(Coeff_Best_Model_1)\n",
    "\n",
    "model_parameters = dataiku.Dataset(\"model_parameters\")\n",
    "model_parameters.write_with_schema(Parameter_Estimates)\n",
    "\n",
    "\n",
    "national_impact = dataiku.Dataset(\"national_impact\")\n",
    "national_impact.write_with_schema(Overall_Impact)\n",
    "\n",
    "Short_Long_Term_Factor = dataiku.Dataset(\"Short_Long_Term_Factor\")\n",
    "Short_Long_Term_Factor.write_with_schema(Data_Summary_Final)\n",
    "\n",
    "ROI = dataiku.Dataset(\"ROI\")\n",
    "ROI.write_with_schema(Final_ROI_df)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_curvature",
  "creator": "can.tan",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  },
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
